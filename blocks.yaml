blocks:
  - id: ocr_stage1
    title: "Stage 1 – Google OCR"
    command: "python batchocr/ocr_tests.py"
    input: pdf
    output: jsonl
    color: blue
    include_in_bootstrap: false

    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
  - id: ocr_stage1
    title: "Stage 1 – Qwen OCR"
    command: "python openocr/ocr_tests.py"
    input: pdf
    output: jsonl
    color: blue
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
  - id: cleanup_stage2
    title: "Stage 2 – Cleanup"
    command: "python cleanocr/cleanup_tests.py"
    input: jsonl
    output: jsonl
    color: green
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: max-tokens
        label: "Max tokens"
        long: --max-tokens
        default: "1200"
        takes_value: true
      - key: keep-original
        label: "Keep original text"
        long: --keep-original
        takes_value: false
        default: false
  - id: evaluation_stage3
    title: "Stage 3 – Eval (summary text)"
    command: "python evaluate/evaluate_tests.py"
    input: jsonl
    output: jsonl
    color: orange
    include_in_bootstrap: false
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: material
        label: "Material"
        long: --material-file
        placeholder: "STRING or PATH"
        default: ""
        takes_value: true
      - key: question
        label: "Question"
        long: --question-file
        placeholder: "STRING or PATH"
        default: ""
        takes_value: true
      - key: context
        label: "Context"
        long: --context
        placeholder: "STRING or PATH"
        default: ""
        takes_value: true
  - id: evaluation_fulltext_stage3
    title: "Stage 3 – Eval (Full Text)"
    command: "python evaluate/evaluate_fulltext.py"
    input: jsonl
    output: jsonl
    color: orange
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: materials-path
        label: "Materials path"
        long: --materials-path
        placeholder: "PATH or DIRECTORY"
        default: ""
        takes_value: true
      - key: question
        label: "Question"
        long: --question-file
        placeholder: "STRING or PATH"
        default: ""
        takes_value: true
      - key: context
        label: "Context"
        long: --context
        placeholder: "STRING or PATH"
        default: ""
        takes_value: true
      - key: no-encrypted-content
        label: "No encrypted content"
        long: --no-encrypted-content
        takes_value: false
        default: false
  - id: evaluation_essay_stage3
    title: "Stage 3 – Evaluation (Essay)"
    command: "python evaluate/evaluate_essay.py"
    input: jsonl
    output: jsonl
    color: orange
    include_in_bootstrap: false
    flags:
      - key: input-path
        label: "Input path"
        long: --input-path
        short: -i
        placeholder: "DIRECTORY or ZIP"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: rubric
        label: "Rubric file"
        long: --rubric-file
        placeholder: "PATH"
        default: ""
        takes_value: true
      - key: pdf-report
        label: "PDF report"
        long: --pdf-report
        placeholder: "PATH"
        default: ""
        takes_value: true
  - id: reporting_stage4
    title: "Stage 4 – Reporting"
    command: "python report/report_results.py"
    input: jsonl
    output: jsonl
    color: red
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: csv
        label: "CSV output"
        long: --csv
        placeholder: "PATH"
        default: ""
        takes_value: true
      - key: pdf-dir
        label: "PDF directory"
        long: --pdf-dir
        placeholder: "DIRECTORY"
        default: ""
        takes_value: true
      - key: grade-max
        label: "Grade max"
        long: --grade-max
        default: "10"
        takes_value: true
      - key: no-pass-through
        label: "Disable JSON passthrough"
        long: --no-pass-through
        takes_value: false
        default: false
  - id: mail_payloads_stage5
    title: "Stage 5 – Mail Payloads"
    command: "python mailroom/mailroom_cli.py"
    input: jsonl
    output: jsonl
    color: blue
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: roster
        label: "Roster CSV"
        long: --roster
        placeholder: "PATH"
        default: ""
        takes_value: true
      - key: subject
        label: "Email subject"
        long: --subject
        default: "Your Evaluation from Mr. Cooper's AI Krew"
        takes_value: true
      - key: greeting
        label: "Greeting prefix"
        long: --greeting
        default: "Hello"
        takes_value: true
      - key: report
        label: "Summary report"
        long: --report
        placeholder: "PATH"
        default: ""
        takes_value: true
  - id: name_review_stage6
    title: "Stage 6 – Name Review"
    command: "python namecorrector/name_corrector.py"
    input: jsonl
    output: jsonl
    color: purple
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: roster-file
        label: "Roster file"
        long: --roster-file
        placeholder: "PATH"
        default: ""
        takes_value: true
      - key: env-file
        label: "Environment file"
        long: --env-file
        placeholder: "PATH"
        default: ""
        takes_value: true
  - id: smtp_send_stage7
    title: "Stage 7 – SMTP Send"
    command: "python mailroom/send_mail.py"
    input: jsonl
    output: jsonl
    color: gray
    flags:
      - key: input
        label: "Input source"
        long: --input
        short: -i
        placeholder: "PATH or -"
        default: ""
        takes_value: true
      - key: output
        label: "Output path"
        long: --output
        short: -o
        placeholder: "PATH (stdout by default)"
        default: ""
        takes_value: true
      - key: dry-run
        label: "Dry run"
        long: --dry-run
        takes_value: false
        default: false
      - key: rate-limit
        label: "Rate limit"
        long: --rate-limit
        default: "0.5"
        takes_value: true
      - key: attach-report
        label: "Attach report PDF"
        long: --attach-report
        takes_value: false
        default: false
      - key: report
        label: "Send summary report"
        long: --report
        placeholder: "PATH"
        default: ""
        takes_value: true
